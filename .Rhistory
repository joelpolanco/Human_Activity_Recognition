tstrain = ts(training$visitsTumblr)
install.packages("forecast")
?bats()
?bats
View(training)
fit <- bats(training, use.parallel=FALSE)
plot(forecast(fit))
library(forecast)
fit <- bats(training, use.parallel=FALSE)
plot(forecast(fit))
?bats
fit <- bats(training$visitsTumblr)
plot(forecast(fit))
library(forecast)
library(quantmod)
# fit a model
fit <- bats(tstrain)
# check how long the test set is, so you can predict beyond trainign
h <- dim(testing)[1]
# forecast the model for remaining time points
fcast <- forecast(fit, level = 95, h = h)
# get the accuracy
accuracy(fcast, testing$visitsTumblr)
# check what percentage of times that the actual number of visitors was within
# 95% confidence interval
result <- c()
l <- length(fcast$lower)
for (i in 1:l){
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result <- c(result, a)
}
sum(result)/l * 100
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
set.seed(325)
library(e1071)
library(caret)
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
prediction <- predict(fit, testing)
accuracy(prediction, testing$CompressiveStrength)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
library(caret)
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
prediction <- predict(fit, testing)
accuracy(prediction, testing$CompressiveStrength)
##
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
library(caret)
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
prediction <- predict(fit, testing)
accuracy(prediction, testing$CompressiveStrength)
results <- c(accsvm[2], accsvmRadial[2], accsvmLinear[2], accsvmPoly[2], accsvmRadial[2], accsvmRadialCost[2])
modelFit4<- svm(CompressiveStrength~.,data=training)
result4<- predict(modelFit4,testing)
accuracy(result4,testing$CompressiveStrength)
install.packages("RODBC")
library('RODBC')
dbhandle <- odbcConnect("ImpalaDSN;pwd=h546443150!!")
input<-sqlQuery(dbhandle, paste("SELECT count(*) FROM IAH_CRM_ANALYSIS.v_f_opp"))
close(dbhandle)
input
install.packages("rJava")
install.packages("RJDBC")
library('RJDBC')
library('RIAHImpala')
rimpala.init(libs='C:/Users/jgpolanc/Desktop/IAH_R/jar')
rimpala.connect('hdprd1.intel.com',
principal="AuthMech=4;SSLTrustStore=C:/Users/jgpolanc/Desktop/IAH_R/jar\\Intel_Root_CA_Chain.jks;SSLTrustStorePwd=changeit;UID=sys_segbi@AMR.CORP.INTEL.COM;PWD=ypaqj06@")
#set working directory
setwd("C:/Users/jgpolanc/Desktop/Coursera/C9/Human_Activity_Recognition")
#Load libraries
library(dplyr)
library(caret)
library(corrgram)
library(randomForest)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
#set working directory
setwd("C:/Users/jgpolanc/Desktop/Coursera/C9/Human_Activity_Recognition")
#Load libraries
library(dplyr)
library(caret)
library(corrgram)
library(randomForest)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
#reproducibility
set.seed(1234)
#Load Data
validation<- read.csv(paste(getwd(),"/data/pml-testing.csv", sep=""),na.strings=c("NA","#DIV/0!",""))
train<- read.csv(paste(getwd(),"/data/pml-training.csv", sep=""),na.strings=c("NA","#DIV/0!",""))
##reorder columns and prep data
train<- train[ ,c(160,1:159)]
validation<- validation[ ,c(160,1:159)]
train[, c(9:160)] <- sapply(train[, c(9:160)], as.numeric)
validation[, c(9:160)] <- sapply(validation[, c(9:160)], as.numeric)
str(train);str(validation)
#data partitioning for training
train_1 <- createDataPartition(y=train$classe, p=0.6, list=FALSE)
train_dat  <- train[train_1, ];test_dat<- train[-train_1, ]
dim(train_dat);dim(test_dat)
#data cleaning, remove zero variability
NZVdat <- nearZeroVar(train_dat, saveMetrics=TRUE)
NZVdat[NZVdat[,"zeroVar"] > 0, ]
NZVdat[NZVdat[,"zeroVar"] + NZVdat[,"nzv"] > 0, ]
nzv <- nearZeroVar(train_dat)
filtered_train <- train_dat[,-nzv]
dim(train_dat); dim(filtered_train)
#identify correlated (numeric predictors)
##-- Notes split filtered train into classe+non-numerics vs numerics and run the code chunk below, then run the high corr chunk and cbind them back together
filtered_train2<-filtered_train[,c(9:130)]
descrCor <-  cor(filtered_train2,use="complete.obs")
summary(descrCor[upper.tri(descrCor)])
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
filteredDescr <- filtered_train2[,-highlyCorDescr]
descrCor2 <- cor(filteredDescr,use="complete.obs")
summary(descrCor2[upper.tri(descrCor2)])
filtered_train3<-filtered_train[,c(1:8)]
highlyCorDescr = sort(highlyCorDescr)
reduced_Data = filtered_train2[,-c(highlyCorDescr)]
## Check to see if there are any linear combinations of data present
reduced_Data2<- reduced_Data[complete.cases(reduced_Data),]
comboInfo <- findLinearCombos(reduced_Data2)
comboInfo
##There are no linear combinations present
final_train<-cbind(filtered_train3,reduced_Data)
# Removing X variable so that it does not interfer with ML Algorithms
final_train <- final_train[c(-2)]
##Remove Variables with too many NAs. Removing variables with a  60% threshold of NAâ€™s
trainingV1 <- final_train #creating another subset to iterate in loop
for(i in 1:length(final_train)) { #for every column in the training dataset
if( sum( is.na( final_train[, i] ) ) /nrow(final_train) >= .6 ) { #if n?? NAs > 60% of total observations
for(j in 1:length(trainingV1)) {
if( length( grep(names(final_train[i]), names(trainingV1)[j]) ) ==1)  { #if the columns are the same:
trainingV1 <- trainingV1[ , -j] #Remove that column
}
}
}
}
#To check the new N?? of observations
dim(trainingV1)
#Setting back to our set:
final_train <- trainingV1
rm(trainingV1)
#Perform the exact same  transformations for testing(test_dat) and valiation(validation) data sets.
clean1 <- colnames(final_train)
clean2 <- colnames(final_train[, -1]) #already with classe column removed
test_dat <- test_dat[clean1]
validation <- validation[clean2]
#To check the new N?? of observations
dim(test_dat)
#To check the new N?? of observations
dim(validation)
#In order to ensure proper functioning of Decision Trees and especially RandomForest Algorithm with the Test data set (data set provided), we need to coerce the data into the same type.
for (i in 1:length(test_dat) ) {
for(j in 1:length(final_train)) {
if( length( grep(names(final_train[i]), names(test_dat)[j]) ) ==1)  {
class(test_dat[j]) <- class(final_train[i])
}
}
}
#In order to ensure proper functioning of Decision Trees and especially RandomForest Algorithm with the Test data set (data set provided), we need to coerce the data into the same type.
for (i in 1:length(validation) ) {
for(j in 1:length(final_train)) {
if( length( grep(names(final_train[i]), names(validation)[j]) ) ==1)  {
class(validation[j]) <- class(final_train[i])
}
}
}
#Double Check it worked
validation <- rbind(final_train[1, -1] , validation) #note row 2 does not mean anything, this will be removed right.. now:
validation <- validation[-1,]
filtered_train2<-filtered_train[,c(9:130)]
filtered_train <- train_dat[,-nzv]
dim(train_dat); dim(filtered_train)
View(filtered_train)
library(dplyr)
library(caret)
library(corrgram)
library(randomForest)
library(rpart)
library(rpart.plot)
#reproducibility
set.seed(1234)
#Load Data
validation<- read.csv(paste(getwd(),"/data/pml-testing.csv", sep=""),na.strings=c("NA","#DIV/0!",""))
train<- read.csv(paste(getwd(),"/data/pml-training.csv", sep=""),na.strings=c("NA","#DIV/0!",""))
##reorder columns and prep data
train<- train[ ,c(160,1:159)]
validation<- validation[ ,c(160,1:159)]
train[, c(9:160)] <- sapply(train[, c(9:160)], as.numeric)
validation[, c(9:160)] <- sapply(validation[, c(9:160)], as.numeric)
str(train);str(validation)
#data partitioning for training
train_1 <- createDataPartition(y=train$classe, p=0.6, list=FALSE)
train_dat  <- train[train_1, ];test_dat<- train[-train_1, ]
dim(train_dat);dim(test_dat)
#data cleaning, remove zero variability
NZVdat <- nearZeroVar(train_dat, saveMetrics=TRUE)
NZVdat[NZVdat[,"zeroVar"] > 0, ]
NZVdat[NZVdat[,"zeroVar"] + NZVdat[,"nzv"] > 0, ]
nzv <- nearZeroVar(train_dat)
filtered_train <- train_dat[,-nzv]
dim(train_dat); dim(filtered_train)
#identify correlated (numeric predictors)
##-- Notes split filtered train into classe+non-numerics vs numerics and run the code chunk below, then run the high corr chunk and cbind them back together
filtered_train2<-filtered_train[,c(9:130)]
descrCor <-  cor(filtered_train2,use="complete.obs")
summary(descrCor[upper.tri(descrCor)])
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
filteredDescr <- filtered_train2[,-highlyCorDescr]
descrCor2 <- cor(filteredDescr,use="complete.obs")
summary(descrCor2[upper.tri(descrCor2)])
filtered_train3<-filtered_train[,c(1:8)]
highlyCorDescr = sort(highlyCorDescr)
reduced_Data = filtered_train2[,-c(highlyCorDescr)]
## Check to see if there are any linear combinations of data present
reduced_Data2<- reduced_Data[complete.cases(reduced_Data),]
comboInfo <- findLinearCombos(reduced_Data2)
comboInfo
##There are no linear combinations present
final_train<-cbind(filtered_train3,reduced_Data)
#set working directory
setwd("C:/Users/jgpolanc/Desktop/Coursera/C9/Human_Activity_Recognition")
#Load libraries
library(dplyr)
library(caret)
library(corrgram)
library(randomForest)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
#reproducibility
set.seed(1234)
#Load Data
validation<- read.csv(paste(getwd(),"/data/pml-testing.csv", sep=""),na.strings=c("NA","#DIV/0!",""))
train<- read.csv(paste(getwd(),"/data/pml-training.csv", sep=""),na.strings=c("NA","#DIV/0!",""))
##reorder columns and prep data
train<- train[ ,c(160,1:159)]
validation<- validation[ ,c(160,1:159)]
train[, c(9:160)] <- sapply(train[, c(9:160)], as.numeric)
validation[, c(9:160)] <- sapply(validation[, c(9:160)], as.numeric)
str(train);str(validation)
train_1 <- createDataPartition(y=train$classe, p=0.6, list=FALSE)
train_dat  <- train[train_1, ];test_dat<- train[-train_1, ]
dim(train_dat);dim(test_dat)
NZVdat <- nearZeroVar(train_dat, saveMetrics=TRUE)
NZVdat[NZVdat[,"zeroVar"] > 0, ]
NZVdat[NZVdat[,"zeroVar"] + NZVdat[,"nzv"] > 0, ]
nzv <- nearZeroVar(train_dat)
filtered_train <- train_dat[,-nzv]
View(filtered_train)
dim(train_dat); dim(filtered_train)
str(filtered_train)
c <- cbind(filtered_train[, which(colnames(filtered_train)%in% colnames(train_dat))],
train_dat[, which(colnames(train_dat)%in% colnames(filtered_train))])
c
c<-colnames(filtered_train)
d<-colnames(train_dat)
colnames(train_dat)
regmatches(c, gregexpr(d, c), invert=TRUE)
regmatches(c, gregexpr(d, c), invert=TRUE)
regmatches(c, gregexpr(d, c))
regmatches(d, gregexpr(c, d), invert=TRUE)
regmatches(d, gregexpr(c, d))
lapply(regmatches(d, gregexpr(c, d), invert=TRUE)
setdiff(c,d)
d[!c %in% d]
c[!d %in% c]
c[d %in% !c]
d[d %in% !c]
View(train_dat)
str(train_dat)
NZVdat <- nearZeroVar(train_dat[,9:160], saveMetrics=TRUE)
NZVdat[NZVdat[,"zeroVar"] > 0, ]
NZVdat[NZVdat[,"zeroVar"] + NZVdat[,"nzv"] > 0, ]
nzv <- nearZeroVar(train_dat)
filtered_train <- train_dat[,-nzv]
dim(train_dat); dim(filtered_train)
str(filtered_train)
NZVdat <- nearZeroVar(train_dat[,9:160], saveMetrics=TRUE)
NZVdat[NZVdat[,"zeroVar"] > 0, ]
NZVdat[NZVdat[,"zeroVar"] + NZVdat[,"nzv"] > 0, ]
nzv <- nearZeroVar(train_dat[,9:160])
filtered_train <- train_dat[,-nzv]
dim(train_dat); dim(filtered_train)
filtered_train2<-filtered_train[,c(9:130)]
descrCor <-  cor(filtered_train2,use="complete.obs")
summary(descrCor[upper.tri(descrCor)])
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
filteredDescr <- filtered_train2[,-highlyCorDescr]
descrCor2 <- cor(filteredDescr,use="complete.obs")
summary(descrCor2[upper.tri(descrCor2)])
filtered_train3<-filtered_train[,c(1:8)]
highlyCorDescr = sort(highlyCorDescr)
reduced_Data = filtered_train2[,-c(highlyCorDescr)]
filtered_train
str(filtered_train)
NZVdat <- nearZeroVar(train_dat[,c(9:160)], saveMetrics=TRUE)
NZVdat[NZVdat[,"zeroVar"] > 0, ]
NZVdat[NZVdat[,"zeroVar"] + NZVdat[,"nzv"] > 0, ]
nzv <- nearZeroVar(train_dat[,C(9:160)]
filtered_train <- train_dat[,-nzv]
dim(train_dat); dim(filtered_train)
nzv <- nearZeroVar(train_dat[,C(9:160)])
nzv <- nearZeroVar(train_dat[,c(9:160)])
filtered_train <- train_dat[,-nzv]
dim(train_dat); dim(filtered_train)
filtered_train2<-filtered_train[,c(9:130)]
descrCor <-  cor(filtered_train2,use="complete.obs")
summary(descrCor[upper.tri(descrCor)])
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
filteredDescr <- filtered_train2[,-highlyCorDescr]
descrCor2 <- cor(filteredDescr,use="complete.obs")
summary(descrCor2[upper.tri(descrCor2)])
filtered_train3<-filtered_train[,c(1:8)]
highlyCorDescr = sort(highlyCorDescr)
reduced_Data = filtered_train2[,-c(highlyCorDescr)]
View(filtered_train)
str(filtered_train)
#set working directory
setwd("C:/Users/jgpolanc/Desktop/Coursera/C9/Human_Activity_Recognition")
#Load libraries
library(dplyr)
library(caret)
library(corrgram)
library(randomForest)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
#reproducibility
set.seed(1234)
#Load Data
validation<- read.csv(paste(getwd(),"/data/pml-testing.csv", sep=""),na.strings=c("NA","#DIV/0!",""))
train<- read.csv(paste(getwd(),"/data/pml-training.csv", sep=""),na.strings=c("NA","#DIV/0!",""))
train<- train[ ,c(160,1:159)]
validation<- validation[ ,c(160,1:159)]
colnames(train)
colnames(validation)
train[, c(9:160)] <- sapply(train[, c(9:160)], as.numeric)
validation[, c(9:160)] <- sapply(validation[, c(9:160)], as.numeric)
str(train);str(validation)
train_1 <- createDataPartition(y=train$classe, p=0.6, list=FALSE)
train_dat  <- train[train_1, ];test_dat<- train[-train_1, ]
dim(train_dat);dim(test_dat)
NZVdat <- nearZeroVar(train_dat[,c(9:160)], saveMetrics=TRUE)
View(NZVdat)
str(NZVdat)
zerovar
NZVdat[NZVdat[,"zeroVar"] + NZVdat[,"nzv"] > 0, ]
nzv <- nearZeroVar(train_dat[,c(9:160)])
filtered_train <- train_dat[,-nzv]
str(filtered_train)
train_subset<-train_dat[,c(9:130)]
NZVdat <- nearZeroVar(train_subset, saveMetrics=TRUE)
NZVdat[NZVdat[,"zeroVar"] + NZVdat[,"nzv"] > 0, ]
#set working directory
setwd("C:/Users/jgpolanc/Desktop/Coursera/C9/Human_Activity_Recognition")
#Load libraries
library(dplyr)
library(caret)
library(corrgram)
library(randomForest)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
#reproducibility
set.seed(1234)
#Load Data
validation<- read.csv(paste(getwd(),"/data/pml-testing.csv", sep=""),na.strings=c("NA","#DIV/0!",""))
train<- read.csv(paste(getwd(),"/data/pml-training.csv", sep=""),na.strings=c("NA","#DIV/0!",""))
##reorder columns and prep data
train<- train[ ,c(160,1:159)]
validation<- validation[ ,c(160,1:159)]
train[, c(9:160)] <- sapply(train[, c(9:160)], as.numeric)
validation[, c(9:160)] <- sapply(validation[, c(9:160)], as.numeric)
str(train);str(validation)
#data partitioning for training
train_1 <- createDataPartition(y=train$classe, p=0.6, list=FALSE)
train_dat  <- train[train_1, ];test_dat<- train[-train_1, ]
dim(train_dat);dim(test_dat)
train_subset1<-train_dat[,c(1:8)]
train_subset<-train_dat[,c(9:130)]
NZVdat <- nearZeroVar(train_subset, saveMetrics=TRUE)
NZVdat[NZVdat[,"zeroVar"] > 0, ]
NZVdat[NZVdat[,"zeroVar"] + NZVdat[,"nzv"] > 0, ]
nzv <- nearZeroVar(train_subset)
train_subset <- train_subset[,-nzv]
filtered_train<-cbind(train_subset1,train_subset)
dim(train_dat); dim(filtered_train)
nzv
str(filtered_train)
descrCor <-  cor(train_subset,use="complete.obs")
summary(descrCor[upper.tri(descrCor)])
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
filteredDescr <- train_subset[,-highlyCorDescr]
descrCor2 <- cor(filteredDescr,use="complete.obs")
summary(descrCor2[upper.tri(descrCor2)])
highlyCorDescr = sort(highlyCorDescr)
reduced_Data = train_subset[,-c(highlyCorDescr)]
reduced_Data2<- reduced_Data[complete.cases(reduced_Data),]
comboInfo <- findLinearCombos(reduced_Data2)
comboInfo
final_train<-cbind(train_subset1,reduced_Data)
str(final_train)
final_train <- final_train[c(-2)]
str(final_train)
trainingV1 <- final_train #creating another subset to iterate in loop
for(i in 1:length(final_train)) { #for every column in the training dataset
if( sum( is.na( final_train[, i] ) ) /nrow(final_train) >= .6 ) { #if n?? NAs > 60% of total observations
for(j in 1:length(trainingV1)) {
if( length( grep(names(final_train[i]), names(trainingV1)[j]) ) ==1)  { #if the columns are the same:
trainingV1 <- trainingV1[ , -j] #Remove that column
}
}
}
}
#To check the new N?? of observations
dim(trainingV1)
#Setting back to our set:
final_train <- trainingV1
rm(trainingV1)
#Perform the exact same  transformations for testing(test_dat) and valiation(validation) data sets.
clean1 <- colnames(final_train)
clean2 <- colnames(final_train[, -1]) #already with classe column removed
test_dat <- test_dat[clean1]
validation <- validation[clean2]
#To check the new N?? of observations
dim(test_dat)
#To check the new N?? of observations
dim(validation)
#In order to ensure proper functioning of Decision Trees and especially RandomForest Algorithm with the Test data set (data set provided), we need to coerce the data into the same type.
for (i in 1:length(test_dat) ) {
for(j in 1:length(final_train)) {
if( length( grep(names(final_train[i]), names(test_dat)[j]) ) ==1)  {
class(test_dat[j]) <- class(final_train[i])
}
}
}
#In order to ensure proper functioning of Decision Trees and especially RandomForest Algorithm with the Test data set (data set provided), we need to coerce the data into the same type.
for (i in 1:length(validation) ) {
for(j in 1:length(final_train)) {
if( length( grep(names(final_train[i]), names(validation)[j]) ) ==1)  {
class(validation[j]) <- class(final_train[i])
}
}
}
#Double Check it worked
validation <- rbind(final_train[1, -1] , validation) #note row 2 does not mean anything, this will be removed right.. now:
validation <- validation[-1,]
Fit1 <- rpart(classe ~ ., data=final_train, method="class")
##To view the decision tree with fancy :
fancyRpartPlot(modFitA1)
fancyRpartPlot(Fit1)
#Predicting:
predict1 <- predict(Fit1, test_dat, type = "class")
##Using confusion Matrix to test results:
confusionMatrix(predictionsA1, myTesting$classe)
confusionMatrix(predict1, test_dat$classe)
#Using ML algorithms for prediction: Random Forests
Fit2 <- randomForest(classe ~. , data=final_train)
##Predicting in-sample error:
predict2 <- predict(Fit2, test_dat, type = "class")
##Using confusion Matrix to test results:
confusionMatrix(predict2, test_dat$classe)
#Generating Files to submit as answers for the Assignment:
##Finally, using the provided Test Set out-of-sample error.
##For Random Forests we use the following formula, which yielded a much better prediction in in-sample:
predict3 <- predict(Fit2, validation, type = "class")
##Function to generate files with predictions to submit for assignment
pml_file = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_file(predict3)
predict3
train_subset1<-train_dat[,c(1:8)]
#Load Data
validation<- read.csv(paste(getwd(),"/data/pml-testing.csv", sep=""),na.strings=c("NA","#DIV/0!",""))
train<- read.csv(paste(getwd(),"/data/pml-training.csv", sep=""),na.strings=c("NA","#DIV/0!",""))
